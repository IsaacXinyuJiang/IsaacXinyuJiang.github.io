<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xinyu Jiang</title>

  <meta name="author" content="Xinyu Jiang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name><i>Isaac Xinyu Jiang (ËíãÊñ∞ÂÆá)</i></name>


                  <p style="font-size: 16px;">I am a junior undergraduate student from
                    South China University of Technology, working with <a href="https://drliuqi.github.io/"> Prof. Qi
                      Liu</a>. </a>.
                    <br>


                  </p>

                  <p style="text-align:center;">
                    <a href="202164020201@mail.scut.edu.cn">Email</a> &nbsp/&nbsp
                    <a href="assets/CV-Jinxiu.pdf">CV</a> &nbsp/&nbsp
                    <!-- <a href="https://scholar.google.com/citations?user=ihuH8uMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp -->
                    <a href="https://github.com/IsaacXinyuJiang">Github</a> &nbsp/&nbsp
                    <!-- <a href="https://twitter.com/weixi_feng">Twitter</a> &nbsp/&nbsp -->

                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/life.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/life.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>



          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading style="font-size: 26px;"><i>Research Interests</i></heading>
                  <p style="font-size: 16px;">

                    My research focuses on <b>computer vision</b>, <b>machine learning</b>, and <b>artificial
                      intelligence</b>, specifically
                    aimed at advancing
                    <b>human-object interaction (HOI)</b> understanding. I specialize in developing innovative
                    algorithms for
                    HOI detection,
                    particularly in weakly supervised learning. My goal is to reduce annotation burdens while
                    maintaining or improving
                    performance. I'm also interested in leveraging cross-modal information like text-image models to
                    enhance HOI detection
                    accuracy. Ultimately, I aim to contribute to more efficient computer vision systems for
                    understanding complex real-world
                    scenes.
                    <!-- While visual inputs have played a more important part, I believe that the two modalities are equally important that work at different levels of abstraction. -->
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading style="font-size: 26px;"><i>Research Experience</i></heading>
                  <p style="font-size: 16px;">


                    <b> School of Future Technology, SCUT </b>
                    <br>
                    Research Intern &emsp; 8/22 ‚Äì present
                    <br>

                    Human-Object Interaction &ensp; advised by <a href="https://drliuqi.github.io/"> Prof. Qi Liu
                      (IEEE Senior Member) </a>.

                    <br>
                    HOI detection aims to recognize interactions between humans and objects in images. Collaborating
                    with mentors and senior
                    students in our Human-Computer Interaction lab, I proposed a label-free training method for HOI
                    models, applied for a
                    patent, and authored a paper submitted to TIP.
                    <br>
                    <br>


                    <b> School of Future Technology, SCUT </b>
                    <br>
                    National Key Project &emsp; 6/23 ‚Äì present
                    <br>
                    Early Disease Detection &ensp; advised by <a
                      href="https://www2.scut.edu.cn/ft/2021/1127/c29779a452822/page.htm"> Prof. Zhanpeng Jin
                    </a>.
                    <br>
                    This is a nationally funded university innovation and entrepreneurship program. We aim to provide a
                    convenient,
                    accurate, and user-friendly tool that utilizes children's gaze and facial features to aid in the
                    early detection of
                    signs of autism. Creating a mobile app for early autism detection, incorporating a gaze estimation
                    model and an autism
                    detection model based on gaze point distribution.
                    <br>
                    <br>



                    <b> Shien-Ming Wu School of Intelligent Engineering, SCUT </b>
                    <br>
                    Student Research Project &emsp; 4/23 ‚Äì present
                    <br>

                    Natural Language Processing &ensp; advised by <a
                      href="https://www2.scut.edu.cn/wusie/2021/1020/c25374a447913/page.htm"> Prof.
                      Ziqian Zeng
                    </a>.

                    <br>
                    Joined the "Research on Inference Optimization Techniques for Transformer Models" SRP project team.
                    The goal of this
                    project is to achieve a 5x acceleration on top of BERT with an accuracy loss of less than 1%.
                    <br>





                  </p>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading style="font-size: 26px;"><i>Education Experience</i></heading>
                  <p style="font-size: 16px;">
                    <b>South China University of Technology (SCUT)</b>, Guangzhou, China &emsp; 09/21 ‚Äì 06/25(expected)
                    <br>

                    B.Eng &ensp; (Majoring in Artificial Intelligence)

                    <br>
                    <!-- <br> -->
                    <!-- <b>GPA:</b> 3.72 / 4.0 -->
                    <!-- <br> -->
                    <br>
                    <b>Main courses:</b> Big Data and Data Mining Course Practicum <b>(4.0/4.0)</b>,&ensp;Deep Learning
                    and Computer Vision Course Design <b>(4.0/4.0)</b>,&ensp;Digital
                    Image Processing <b>(4.0/4.0)</b>,&ensp;</b> Machine Learning Course Design <b>(4.0/4.0)</b>,&ensp;
                    C++ Programming Foundations I & II <b>(4.0/4.0)</b>,&ensp; Python Programming
                    <b>(4.0/4.0)</b>,&ensp; Artificial Intelligence and 3D
                    Vision<b>(4.0/4.0)</b>,&ensp;Linear Algebra and Analytical Geometry<b>(4.0/4.0)</b>,&ensp; Calculus
                    I & II <b>(4.0/4.0)</b>......

                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading style="font-size: 26px;"><i>Awards</i></heading>
                  <p style="font-size: 16px;">

                    <li>The Taihu Innovation Scholarship (<b>ranked 1/160 comprehensively</b>,&ensp; Ôø•8000, Wuxi city
                      governments) </li>
                    <li>TCL Corporate Scholarships (<b>ranked 1/40 comprehensively</b>,&ensp; Ôø•20000, TCL Technology)
                    </li>
                    <li>SCUT School Scholarship (<b>ranked 1/40 comprehensively</b>, Ôø•20000, SCUT) </li>
                    <li>Asia and Pacific Mathematical Contest in Modeling (APMCM) -- The Third Prize
                    </li>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading style="font-size: 26px;"><i>Publication</i></heading>
                </td>
              </tr>
            </tbody>
          </table>











          <table
            style="width:100%;border:0px;border-spacing:10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/FreeA.png" alt="layoutgpt_gif" width="200" height="150 " style="border-style: none">
                </td>
                <td width="75%" valign="middle">
                  <a href="">
                    <papertitle>FreeA: Human-object Interaction Detection using Free Annotation Labels
                    </papertitle>
                  </a>
                  <br><br>
                  <a href="" style="color: black;">Yuxiao Wang</a>, &nbsp;
                  <a href="" style="color: black;">Zhenao Wei</a>, &nbsp;
                  <strong style="color: #0F52BA;">Xinyu Jiang</strong>, &nbsp;
                  <a href="" style="color: black;">Yu Lei</a>, &nbsp;
                  <a href="" style="color: black;">Weiying Xue</a>, &nbsp;
                  <a href="" style="color: black;">Jinxiu Liu</a>, &nbsp;
                  <a href="https://drliuqi.github.io/" style="color: black;">Qi Liu</a>, &nbsp;
                  <!-- <b>(* contribute equally)</b> -->

                  <!-- <a href="https://tsujuifu.github.io/" style="color: black;">Tsu-Jui Fu</a>, &nbsp;
                <a href="https://varunjampani.github.io/" style="color: black;">Varun Jampani</a>, &nbsp;
                <a href="https://www.arjunakula.com/" style="color: black;">Arjun Akula</a>, &nbsp;
                <a href="https://scholar.google.com/citations?user=kDzxOzUAAAAJ&hl=en" style="color: black;">Xuehai He</a>, &nbsp;
                <a href="https://sites.google.com/site/sugatobasu/" style="color: black;">Sugato Basu</a>, &nbsp;
                <a href="https://eric-xw.github.io/" style="color: black;">Xin Eric Wang</a>, &nbsp;
                <a href="https://sites.cs.ucsb.edu/~william/" style="color: black;">William Yang Wang</a> -->
                  <br>
                  <br>
                  In this paper, we propose a novel self-adaption language-driven HOI detection method, termed
                  as FreeA, without labeling
                  by leveraging the adaptability of CLIP to generate latent HOI labels. To be specific, FreeA
                  matches image features of
                  human-object pairs with HOI text templates, and a priori knowledge-based mask method is
                  developed to suppress improbable
                  interactions. In addition, FreeA utilizes the proposed interaction correlation matching method
                  to enhance the likelihood
                  of actions related to a specified action, further refine the generated HOI labels. Experiments
                  on two benchmark datasets
                  show that FreeA achieves state-of-the-art performance among weakly supervised HOI models. Our
                  approach is +8.58 mean
                  Average Precision (mAP) on HICO-DET and +1.23 mAP on V-COCO more accurate in localizing and
                  classifying the interactive
                  actions than the newest weakly model, and +1.68 mAP and +7.28 mAP than the latest weakly+
                  model, respectively. <br>
                  <br>
                  <em style="font-size: 16px;">IEEE Transactions on Image Processing, under review</em>
                  <br>
                  <!-- <a href="">paper (Attached by email)</a> /  -->
                  <!-- <a href="https://layoutgpt.github.io">project page</a>  -->
                  <!-- / <a href="https://github.com/weixi-feng/LayoutGPT">code</a> -->
                  <p></p>
                </td>
              </tr>


              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:0px">
                      <br>
                      <p style="text-align:center;font-size:small;">
                        Template from <a href="https://jonbarron.info/">Jon Barron</a>.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>
        </td>
      </tr>
  </table>
</body>

</html>